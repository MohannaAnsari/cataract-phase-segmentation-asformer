{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6d4f5e-9670-48ab-95b2-053ba67d21f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, yaml, torch, numpy as np, matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ad66d7-9477-4f70-b8b8-d48761fd6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"video_root\": \"data/videos\",\n",
    "    \"segments_csv\": \"data/annotations_segments.csv\",\n",
    "    \"features_train\": \"outputs/features/train/\",\n",
    "    \"features_val\": \"outputs/features/val/\",\n",
    "    \"labels_train\": \"outputs/labels/train/\",\n",
    "    \"labels_val\": \"outputs/labels/val/\",\n",
    "    \"models\": \"outputs/models/\"\n",
    "}\n",
    "os.makedirs(paths[\"features_train\"], exist_ok=True)\n",
    "os.makedirs(paths[\"features_val\"], exist_ok=True)\n",
    "os.makedirs(paths[\"labels_train\"], exist_ok=True)\n",
    "os.makedirs(paths[\"labels_val\"], exist_ok=True)\n",
    "os.makedirs(paths[\"models\"], exist_ok=True)\n",
    "\n",
    "# Dataset info\n",
    "NUM_CLASSES = 10\n",
    "FRAME_STEP = 2       # sample every 2nd frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265e918d-e7bb-40d0-a8f5-fcac1f2f5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])  # remove FC layer\n",
    "model.to(device).eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # converts numpy â†’ tensor\n",
    "    transforms.Resize((224,224)),       # works on tensors in recent torchvision\n",
    "    transforms.Normalize(mean=[0.45]*3, std=[0.225]*3)\n",
    "])\n",
    "\n",
    "\n",
    "def extract_video_features(video_path, out_path, step=FRAME_STEP):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    feats = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = transform(frame).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            feat = model(frame).squeeze().cpu().numpy()   # [512]\n",
    "        feats.append(feat)\n",
    "        for _ in range(step-1): cap.grab()\n",
    "    cap.release()\n",
    "    np.save(out_path, np.stack(feats))\n",
    "\n",
    "# Example extraction for one video (train or val)\n",
    "# sample_video = os.listdir(paths[\"video_root\"])[0]\n",
    "# extract_video_features(os.path.join(paths[\"video_root\"], sample_video),\n",
    "#                        os.path.join(paths[\"features_train\"], sample_video.replace(\".mp4\",\".npy\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13e4f40d-3314-4673-8e63-2e659f38d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done âœ…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "segments = pd.read_csv(paths[\"segments_csv\"])\n",
    "\n",
    "def generate_labels_for_video(video_id, out_path, fps_sample=25//FRAME_STEP):\n",
    "    segs = segments[segments[\"VideoID\"]==video_id]\n",
    "    total = int(segs[\"End\"].max()/FRAME_STEP)\n",
    "    labels = np.zeros(total, dtype=np.int32)\n",
    "    for _, row in segs.iterrows():\n",
    "        s, e, pid = int(row[\"Start\"]/FRAME_STEP), int(row[\"End\"]/FRAME_STEP), int(row[\"PhaseID\"])\n",
    "        labels[s:e] = pid-1\n",
    "        # print(labels)\n",
    "    np.save(out_path, labels)\n",
    "\n",
    "for vid in segments[\"VideoID\"].unique():\n",
    "    split = \"train\" if vid%5!=0 else \"val\"     # 80/20 split\n",
    "    out_dir = paths[\"labels_train\"] if split==\"train\" else paths[\"labels_val\"]\n",
    "    generate_labels_for_video(vid, os.path.join(out_dir, f\"case_{vid:03d}.npy\"))\n",
    "\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4109e5c-cd7f-4a38-9eb9-1abf96a537ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_745\n",
      "case_745 Done âœ…\n",
      "case_749\n",
      "case_749 Done âœ…\n",
      "case_750\n",
      "case_750 Done âœ…\n",
      "case_751\n",
      "case_751 Done âœ…\n",
      "case_760\n",
      "case_760 Done âœ…\n",
      "case_764\n",
      "case_764 Done âœ…\n",
      "case_768\n",
      "case_768 Done âœ…\n",
      "case_770\n",
      "case_770 Done âœ…\n",
      "case_771\n",
      "case_771 Done âœ…\n",
      "case_778\n",
      "case_778 Done âœ…\n",
      "case_781\n",
      "case_781 Done âœ…\n",
      "case_784\n",
      "case_784 Done âœ…\n",
      "case_785\n",
      "case_785 Done âœ…\n",
      "case_786\n",
      "case_786 Done âœ…\n",
      "case_788\n",
      "case_788 Done âœ…\n",
      "case_796\n",
      "case_796 Done âœ…\n",
      "case_797\n",
      "case_797 Done âœ…\n",
      "case_799\n",
      "case_799 Done âœ…\n",
      "case_801\n",
      "case_801 Done âœ…\n",
      "case_802\n",
      "case_802 Done âœ…\n",
      "case_804\n",
      "case_804 Done âœ…\n",
      "case_806\n",
      "case_806 Done âœ…\n",
      "case_807\n",
      "case_807 Done âœ…\n",
      "case_808\n",
      "case_808 Done âœ…\n",
      "case_809\n",
      "case_809 Done âœ…\n",
      "case_810\n",
      "case_810 Done âœ…\n",
      "case_817\n",
      "case_817 Done âœ…\n",
      "case_821\n",
      "case_821 Done âœ…\n",
      "case_825\n",
      "case_825 Done âœ…\n",
      "case_827\n",
      "case_827 Done âœ…\n",
      "case_828\n",
      "case_828 Done âœ…\n",
      "case_829\n",
      "case_829 Done âœ…\n",
      "case_830\n",
      "case_830 Done âœ…\n",
      "case_834\n",
      "case_834 Done âœ…\n",
      "case_835\n",
      "case_835 Done âœ…\n",
      "case_840\n",
      "case_840 Done âœ…\n",
      "case_841\n",
      "case_841 Done âœ…\n",
      "case_845\n",
      "case_845 Done âœ…\n",
      "case_846\n",
      "case_846 Done âœ…\n",
      "case_847\n",
      "case_847 Done âœ…\n",
      "case_849\n",
      "case_849 Done âœ…\n",
      "case_850\n",
      "case_850 Done âœ…\n",
      "case_853\n",
      "case_853 Done âœ…\n",
      "case_855\n",
      "case_855 Done âœ…\n",
      "case_856\n",
      "case_856 Done âœ…\n",
      "case_857\n",
      "case_857 Done âœ…\n",
      "case_861\n",
      "case_861 Done âœ…\n",
      "case_863\n",
      "case_863 Done âœ…\n",
      "case_865\n",
      "case_865 Done âœ…\n",
      "case_866\n",
      "case_866 Done âœ…\n",
      "case_867\n",
      "case_867 Done âœ…\n",
      "case_868\n",
      "case_868 Done âœ…\n",
      "case_871\n",
      "case_871 Done âœ…\n",
      "case_880\n",
      "case_880 Done âœ…\n",
      "case_882\n",
      "case_882 Done âœ…\n",
      "case_883\n",
      "case_883 Done âœ…\n",
      "case_884\n",
      "case_884 Done âœ…\n",
      "case_886\n",
      "case_886 Done âœ…\n",
      "case_887\n",
      "case_887 Done âœ…\n",
      "case_889\n",
      "case_889 Done âœ…\n",
      "case_890\n",
      "case_890 Done âœ…\n",
      "case_891\n",
      "case_891 Done âœ…\n",
      "case_892\n",
      "case_892 Done âœ…\n",
      "case_895\n",
      "case_895 Done âœ…\n",
      "case_896\n",
      "case_896 Done âœ…\n",
      "case_898\n",
      "case_898 Done âœ…\n",
      "case_899\n",
      "case_899 Done âœ…\n",
      "case_900\n",
      "case_900 Done âœ…\n",
      "case_901\n",
      "case_901 Done âœ…\n",
      "case_902\n",
      "case_902 Done âœ…\n",
      "case_906\n",
      "case_906 Done âœ…\n",
      "case_907\n",
      "case_907 Done âœ…\n",
      "case_908\n",
      "case_908 Done âœ…\n",
      "case_909\n",
      "case_909 Done âœ…\n",
      "case_911\n",
      "case_911 Done âœ…\n",
      "case_921\n",
      "case_921 Done âœ…\n",
      "case_922\n",
      "case_922 Done âœ…\n",
      "case_925\n",
      "case_925 Done âœ…\n",
      "case_926\n",
      "case_926 Done âœ…\n",
      "case_928\n",
      "case_928 Done âœ…\n",
      "case_929\n",
      "case_929 Done âœ…\n",
      "case_931\n",
      "case_931 Done âœ…\n",
      "case_932\n",
      "case_932 Done âœ…\n",
      "case_933\n",
      "case_933 Done âœ…\n",
      "case_934\n",
      "case_934 Done âœ…\n",
      "Done âœ…\n"
     ]
    }
   ],
   "source": [
    "for vid in segments[\"VideoID\"].unique():\n",
    "    if vid > 739:\n",
    "        print(f\"case_{vid:03d}\")\n",
    "        split = \"train\" if vid%5!=0 else \"val\"     # 80/20 split\n",
    "        out_dir = paths[\"features_train\"] if split==\"train\" else paths[\"features_val\"]\n",
    "        extract_video_features(os.path.join(paths[\"video_root\"], f\"case_{vid:03d}.mp4\"),\n",
    "                           os.path.join(out_dir, f\"case_{vid:03d}.npy\"))\n",
    "        print(f\"case_{vid:03d} Done âœ…\")\n",
    "    else:\n",
    "        continue\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6e14e4-bc9a-4f52-84f0-f6973e5c40fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ CUDA is available! 1 GPU(s) detected.\n",
      "\n",
      "Device 0: NVIDIA A100-SXM4-40GB\n",
      "  Memory: 39.38 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"ðŸŸ¢ CUDA is available! {num_devices} GPU(s) detected.\\n\")\n",
    "    for i in range(num_devices):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"ðŸ”´ CUDA is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db62183e-387c-4aa8-8751-115d37eddc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done âœ…\n"
     ]
    }
   ],
   "source": [
    "class DilatedResidualLayer(nn.Module):\n",
    "    def __init__(self, in_channels, dilation):\n",
    "        super().__init__()\n",
    "        self.conv_dil = nn.Conv1d(in_channels, in_channels, 3,\n",
    "                                  padding=dilation, dilation=dilation)\n",
    "        self.conv_1x1 = nn.Conv1d(in_channels, in_channels, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out = self.conv_dil(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv_1x1(out)\n",
    "        return out + x\n",
    "\n",
    "class ASFormer(nn.Module):\n",
    "    def __init__(self, in_dim=512, num_classes=NUM_CLASSES,\n",
    "                 d_model=256, n_heads=4, n_blocks=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv1d(in_dim, d_model, 1)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads,\n",
    "            dim_feedforward=2*d_model, dropout=0.1,\n",
    "            activation='gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(enc, num_layers=n_blocks)\n",
    "        self.residuals = nn.Sequential(\n",
    "            DilatedResidualLayer(d_model,1),\n",
    "            DilatedResidualLayer(d_model,2),\n",
    "            DilatedResidualLayer(d_model,4)\n",
    "        )\n",
    "        self.classifier = nn.Conv1d(d_model, num_classes, 1)\n",
    "    def forward(self, x):   # [B,C,T]\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.input_proj(x.transpose(1,2)).transpose(1,2)\n",
    "        x = self.transformer(x)\n",
    "        x = x.transpose(1,2)\n",
    "        x = self.residuals(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2dced3-c738-4b16-baa6-16e206a72c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done âœ…\n"
     ]
    }
   ],
   "source": [
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, feat_dir, label_dir):\n",
    "        self.videos = sorted(os.listdir(feat_dir))\n",
    "        self.feat_dir, self.label_dir = feat_dir, label_dir\n",
    "    def __len__(self): return len(self.videos)\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.videos[idx]\n",
    "        x = np.load(os.path.join(self.feat_dir, name))  # [T,512]\n",
    "        y = np.load(os.path.join(self.label_dir, name)) # [T]\n",
    "        x = torch.tensor(x.T, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_ds = FeatureDataset(paths[\"features_train\"], paths[\"labels_train\"])\n",
    "val_ds   = FeatureDataset(paths[\"features_val\"],   paths[\"labels_val\"])\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec5ce6b-3a36-45ad-a89c-6edfd4d2e932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100% 78/78 [00:07<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100% 78/78 [00:03<00:00, 20.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100% 78/78 [00:03<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100% 78/78 [00:04<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100% 78/78 [00:03<00:00, 20.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100% 78/78 [00:03<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100% 78/78 [00:03<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100% 78/78 [00:03<00:00, 20.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.1045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100% 78/78 [00:03<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100% 78/78 [00:03<00:00, 20.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.0794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100% 78/78 [00:03<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100% 78/78 [00:03<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100% 78/78 [00:03<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100% 78/78 [00:04<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss=0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100% 78/78 [00:04<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train_loss=0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100% 78/78 [00:04<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train_loss=0.0551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100% 78/78 [00:04<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train_loss=0.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100% 78/78 [00:03<00:00, 20.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train_loss=0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100% 78/78 [00:03<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | train_loss=0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100% 78/78 [00:03<00:00, 20.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | train_loss=0.0466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100% 78/78 [00:04<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | train_loss=0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100% 78/78 [00:03<00:00, 20.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | train_loss=0.0360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100% 78/78 [00:03<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | train_loss=0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100% 78/78 [00:03<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | train_loss=0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100% 78/78 [00:04<00:00, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | train_loss=0.0328\n",
      "Done âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ASFormer(in_dim=512).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_loss = np.inf\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(X)\n",
    "        T = min(yhat.shape[-1], y.shape[-1])\n",
    "        yhat = yhat[:, :, :T]\n",
    "        y = y[:, :T]\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    val_loss = np.mean(losses)\n",
    "    print(f\"Epoch {epoch+1:02d} | train_loss={val_loss:.4f}\")\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(paths[\"models\"], \"asformer_best.pth\"))\n",
    "\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4989d51-bf20-46a0-9d69-a9e3af02791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100% 78/78 [00:04<00:00, 16.14it/s]\n",
      "Epoch 1 [Val]: 100% 23/23 [00:01<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train: loss=0.311, acc=0.936 | Val: loss=0.187, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100% 78/78 [00:04<00:00, 16.58it/s]\n",
      "Epoch 2 [Val]: 100% 23/23 [00:00<00:00, 40.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train: loss=0.218, acc=0.952 | Val: loss=0.196, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100% 78/78 [00:04<00:00, 17.95it/s]\n",
      "Epoch 3 [Val]: 100% 23/23 [00:00<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train: loss=0.204, acc=0.952 | Val: loss=0.151, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100% 78/78 [00:03<00:00, 19.86it/s]\n",
      "Epoch 4 [Val]: 100% 23/23 [00:00<00:00, 36.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train: loss=0.175, acc=0.954 | Val: loss=0.139, acc=0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100% 78/78 [00:03<00:00, 20.65it/s]\n",
      "Epoch 5 [Val]: 100% 23/23 [00:00<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train: loss=0.156, acc=0.956 | Val: loss=0.149, acc=0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100% 78/78 [00:03<00:00, 19.84it/s]\n",
      "Epoch 6 [Val]: 100% 23/23 [00:00<00:00, 40.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train: loss=0.136, acc=0.963 | Val: loss=0.180, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100% 78/78 [00:04<00:00, 18.78it/s]\n",
      "Epoch 7 [Val]: 100% 23/23 [00:00<00:00, 39.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train: loss=0.130, acc=0.961 | Val: loss=0.140, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100% 78/78 [00:04<00:00, 19.39it/s]\n",
      "Epoch 8 [Val]: 100% 23/23 [00:00<00:00, 37.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train: loss=0.109, acc=0.968 | Val: loss=0.126, acc=0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100% 78/78 [00:04<00:00, 19.28it/s]\n",
      "Epoch 9 [Val]: 100% 23/23 [00:00<00:00, 38.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train: loss=0.101, acc=0.968 | Val: loss=0.132, acc=0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100% 78/78 [00:03<00:00, 20.75it/s]\n",
      "Epoch 10 [Val]: 100% 23/23 [00:00<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train: loss=0.076, acc=0.974 | Val: loss=0.149, acc=0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100% 78/78 [00:04<00:00, 19.43it/s]\n",
      "Epoch 11 [Val]: 100% 23/23 [00:00<00:00, 39.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train: loss=0.081, acc=0.970 | Val: loss=0.150, acc=0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100% 78/78 [00:03<00:00, 20.65it/s]\n",
      "Epoch 12 [Val]: 100% 23/23 [00:00<00:00, 39.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train: loss=0.072, acc=0.974 | Val: loss=0.146, acc=0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100% 78/78 [00:03<00:00, 21.56it/s]\n",
      "Epoch 13 [Val]: 100% 23/23 [00:00<00:00, 45.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train: loss=0.065, acc=0.978 | Val: loss=0.121, acc=0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100% 78/78 [00:03<00:00, 19.85it/s]\n",
      "Epoch 14 [Val]: 100% 23/23 [00:00<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train: loss=0.057, acc=0.979 | Val: loss=0.123, acc=0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100% 78/78 [00:03<00:00, 19.52it/s]\n",
      "Epoch 15 [Val]: 100% 23/23 [00:00<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train: loss=0.061, acc=0.978 | Val: loss=0.150, acc=0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100% 78/78 [00:03<00:00, 20.02it/s]\n",
      "Epoch 16 [Val]: 100% 23/23 [00:00<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train: loss=0.058, acc=0.980 | Val: loss=0.161, acc=0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100% 78/78 [00:03<00:00, 21.10it/s]\n",
      "Epoch 17 [Val]: 100% 23/23 [00:00<00:00, 37.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train: loss=0.071, acc=0.978 | Val: loss=0.189, acc=0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100% 78/78 [00:04<00:00, 19.36it/s]\n",
      "Epoch 18 [Val]: 100% 23/23 [00:00<00:00, 45.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train: loss=0.071, acc=0.977 | Val: loss=0.161, acc=0.963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Train]: 100% 78/78 [00:03<00:00, 20.46it/s]\n",
      "Epoch 19 [Val]: 100% 23/23 [00:00<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train: loss=0.047, acc=0.983 | Val: loss=0.147, acc=0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Train]: 100% 78/78 [00:03<00:00, 20.66it/s]\n",
      "Epoch 20 [Val]: 100% 23/23 [00:00<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train: loss=0.039, acc=0.986 | Val: loss=0.140, acc=0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Train]: 100% 78/78 [00:03<00:00, 20.75it/s]\n",
      "Epoch 21 [Val]: 100% 23/23 [00:00<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train: loss=0.038, acc=0.986 | Val: loss=0.143, acc=0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Train]: 100% 78/78 [00:04<00:00, 18.79it/s]\n",
      "Epoch 22 [Val]: 100% 23/23 [00:00<00:00, 29.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train: loss=0.038, acc=0.986 | Val: loss=0.148, acc=0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Train]: 100% 78/78 [00:04<00:00, 18.05it/s]\n",
      "Epoch 23 [Val]: 100% 23/23 [00:00<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train: loss=0.036, acc=0.987 | Val: loss=0.159, acc=0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Train]: 100% 78/78 [00:03<00:00, 20.33it/s]\n",
      "Epoch 24 [Val]: 100% 23/23 [00:00<00:00, 42.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train: loss=0.034, acc=0.987 | Val: loss=0.175, acc=0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Train]: 100% 78/78 [00:03<00:00, 20.08it/s]\n",
      "Epoch 25 [Val]: 100% 23/23 [00:00<00:00, 37.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train: loss=0.027, acc=0.990 | Val: loss=0.173, acc=0.966\n",
      "Done âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = ASFormer(in_dim=512, num_classes=10).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "def accuracy(yhat, y):\n",
    "    \"\"\"Compute frame-wise accuracy.\"\"\"\n",
    "    preds = torch.argmax(yhat, dim=1)      # [B, T]\n",
    "    correct = (preds == y).float().sum()\n",
    "    total = torch.numel(y)\n",
    "    return (correct / total).item()\n",
    "\n",
    "for epoch in range(25):\n",
    "    # -------------------- TRAIN --------------------\n",
    "    model.train()\n",
    "    tr_losses, tr_accs = [], []\n",
    "\n",
    "    for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        yhat = model(X)            # [B, C, T]\n",
    "        T = min(yhat.shape[-1], y.shape[-1])\n",
    "        yhat, y = yhat[:, :, :T], y[:, :T]\n",
    "\n",
    "        loss = criterion(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "        tr_accs.append(accuracy(yhat, y))\n",
    "\n",
    "    tr_loss = np.mean(tr_losses)\n",
    "    tr_acc = np.mean(tr_accs)\n",
    "\n",
    "    # -------------------- VALIDATION --------------------\n",
    "    model.eval()\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            yhat = model(X)\n",
    "            T = min(yhat.shape[-1], y.shape[-1])\n",
    "            yhat, y = yhat[:, :, :T], y[:, :T]\n",
    "\n",
    "            val_losses.append(criterion(yhat, y).item())\n",
    "            val_accs.append(accuracy(yhat, y))\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = np.mean(val_accs)\n",
    "\n",
    "    # -------------------- PRINT SUMMARY --------------------\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train: loss={tr_loss:.3f}, acc={tr_acc:.3f} | \"\n",
    "          f\"Val: loss={val_loss:.3f}, acc={val_acc:.3f}\")\n",
    "\n",
    "    # -------------------- SAVE BEST --------------------\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(paths[\"models\"], \"asformer_best.pth\"))\n",
    "\n",
    "print(\"Done âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8be7264-1bde-4fdc-ad42-2816de8a74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100% 23/23 [00:00<00:00, 30.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Accuracy: 0.966\n",
      "Mean F1-score: 0.651\n",
      "Done âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(paths[\"models\"], \"asformer_best.pth\")))\n",
    "model.eval()\n",
    "\n",
    "accs, f1s = [], []\n",
    "\n",
    "for X, y in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "    X = X.to(device)\n",
    "    y = y.squeeze(0).cpu().numpy()                # âœ… flatten ground truth\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X).squeeze(0).cpu().numpy()  # [num_classes, T]\n",
    "        pred = pred.argmax(0)                     # [T]\n",
    "\n",
    "    T = min(len(pred), len(y))\n",
    "    accs.append(accuracy_score(y[:T], pred[:T]))\n",
    "    f1s.append(f1_score(y[:T], pred[:T], average='macro'))\n",
    "\n",
    "print(f\"\\nMean Accuracy: {np.mean(accs):.3f}\")\n",
    "print(f\"Mean F1-score: {np.mean(f1s):.3f}\")\n",
    "\n",
    "print(\"Done âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7bd120-72b2-47a9-8052-1fa404a48294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8gAAAEnCAYAAAB132p8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOrNJREFUeJzt3X18zfXj//Hn2dXZhVmM2dZczEXM9ZhymaQrUbr4Vp/oQvgUoan0QSoSRp/qxocPSkJF+HxCksi1Tz8klyEpRMoWiVnY7OL1+0M7OXa2nTPb2dnZ4367He2836/3+/0653XWXs/zfr9fL4sxxggAAAAAgHLOp7QrAAAAAACAJyAgAwAAAAAgAjIAAAAAAJIIyAAAAAAASCIgAwAAAAAgiYAMAAAAAIAkAjIAAAAAAJIIyAAAAAAASCIgAwAAAAAgiYAMAJA0e/ZsWSwW28PPz08xMTF64okn9Msvv+Qpt23btlKsrfNq1apl97rye8yePVujRo2SxWIplXquX79eFotF69evty0rzfrcdNNNdu9PUFCQmjVrpokTJyonJ6fEj+/o/ejVq5dq1arl8r6mTp2q2bNn51l+5MgRW9sDAJDLr7QrAADwHLNmzVKDBg104cIFbdy4UUlJSdqwYYP27NmjkJCQ0q6eyxYvXqyMjAzb83fffVczZ87UihUrFBYWZltep04dZWRk6I477iiNajrUt2/fUq1P7dq1NXfuXEnSiRMnNH36dD377LNKTk7WhAkT3F6fl19+WYmJiS5vN3XqVFWpUkW9evWyWx4VFaXNmzerTp06xVRDAIA3ICADAGwaN26shIQESVKnTp2UnZ2t1157TUuWLFHPnj1LuXaui4+Pt3u+YsUKSVLLli1VpUqVPOVjYmLcUi9nxMTElGp9goKC1Lp1a9vzLl26qEGDBpoyZYrGjBkjf3//PNsYY5Senq6goKBir09xB1mr1Wr3+gAAkLjEGgBQgNwAcfToUbvlaWlp6t+/v6pUqaLw8HDdd999On78uF2ZBQsW6LbbblNUVJSCgoIUFxenYcOG6dy5c3blDh8+rL/97W+Kjo6W1WpVtWrV1LlzZ+3atSvP/tq0aaOQkBBVqFBBt99+u3bu3Flsr9XRJc21atVSt27dtGzZMsXHx9tex7JlyyRduuQ8Li5OISEhuv766x1eer5t2zbdfffdqly5sgIDAxUfH6+FCxdeVX1WrFihFi1aKCgoSA0aNNB7772XZ/uUlBQ99dRTiomJUUBAgGJjY/Xqq68qKyvLlbfFxt/fXy1bttT58+d18uRJSZLFYtHAgQM1ffp0xcXFyWq1as6cOZKkH374QT169FBERISsVqvi4uL073//O89+v/vuO91xxx0KDg5WlSpV1K9fP6WlpeUp5+gS65ycHE2ePFnNmzdXUFCQrrnmGrVu3VpLly61vV/79u3Thg0bbJeL5+4jv0usv/zyS3Xu3FmhoaEKDg5W27Zt9dlnn9mVyb3VYN26dYX+HgAAyhYCMgAgXwcPHpQkVa1a1W5537595e/vr3nz5un111/X+vXr9cgjj9iV+eGHH3TnnXfaLmkePHiwFi5cqLvuusuu3J133qnt27fr9ddf16pVqzRt2jTFx8frzJkztjLjxo3Tww8/rIYNG2rhwoX64IMPlJaWpg4dOujbb78tmRf/p927d2v48OEaOnSoFi1apLCwMN13330aOXKk3n33XY0bN05z585VamqqunXrpgsXLti2Xbdundq1a6czZ85o+vTp+uSTT9S8eXM99NBDRb73dffu3Xr++ef17LPP6pNPPlHTpk3Vp08fbdy40VYmJSVF119/vVauXKlXXnlFn3/+ufr06aOkpCT9/e9/L/J7cejQIfn5+alSpUq2ZUuWLNG0adP0yiuvaOXKlbY2adWqlfbu3as333xTy5YtU9euXfXMM8/o1VdftW3766+/qmPHjtq7d6+mTp2qDz74QH/88YcGDhzoVH169eqlxMREtWrVSgsWLND8+fN1991368iRI5IuXWJfu3ZtxcfHa/Pmzdq8ebMWL16c7/42bNigm2++WampqZo5c6Y++ugjhYaG6q677tKCBQvylHfm9wAAUMYYAEC5N2vWLCPJbNmyxWRmZpq0tDSzbNkyU7VqVRMaGmpSUlLsyj399NN227/++utGkklOTna4/5ycHJOZmWk2bNhgJJndu3cbY4z57bffjCQzceLEfOv2008/GT8/PzNo0CC75WlpaSYyMtI8+OCDTr/OkSNHGknm5MmT+a67XM2aNU1QUJD5+eefbct27dplJJmoqChz7tw52/IlS5YYSWbp0qW2ZQ0aNDDx8fEmMzPTbr/dunUzUVFRJjs72xhjzLp164wks27dukLrExgYaI4ePWpbduHCBVO5cmXz1FNP2ZY99dRTpkKFCnbljDHmjTfeMJLMvn378n2PjDGmY8eOplGjRiYzM9NkZmaa48ePm2HDhhlJ5oEHHrCVk2TCwsLM77//brf97bffbmJiYkxqaqrd8oEDB5rAwEBb+aFDhxqLxWJ27dplV+7WW2/N8348/vjjpmbNmrbnGzduNJLMiBEjCnwtjRo1Mh07dsyz/McffzSSzKxZs2zLWrdubSIiIkxaWpptWVZWlmncuLGJiYkxOTk5xpii/x4AADwfZ5ABADatW7eWv7+/QkND1a1bN0VGRurzzz9XtWrV7Mrdfffdds+bNm0qyf5S7MOHD6tHjx6KjIyUr6+v/P391bFjR0nS/v37JUmVK1dWnTp19M9//lNvvfWWdu7cmWeU5JUrVyorK0uPPfaYsrKybI/AwEB17NjRbqTjktC8eXNde+21tudxcXGSLo30HBwcnGd57ntw8OBBfffdd7Z7ty+v+5133qnk5GQdOHCgSPWpUaOG7XlgYKCuu+46u/d+2bJl6tSpk6Kjo+2O26VLF0mXzpQWZt++ffL395e/v7+io6P15ptvqmfPnpoxY4ZduZtvvtnujHJ6errWrFmje++9V8HBwXled3p6urZs2SLp0hn2Ro0aqVmzZnb77NGjR6H1+/zzzyVJAwYMKLSsM86dO6evvvpK//d//6cKFSrYlvv6+urRRx/Vzz//nKe9nPk9AACULQzSBQCwef/99xUXFyc/Pz9Vq1ZNUVFRDsuFh4fbPbdarZJku7z4jz/+UIcOHRQYGKgxY8bouuuuU3BwsI4dO6b77rvPVs5isWjNmjUaPXq0Xn/9dT3//POqXLmyevbsqbFjxyo0NFS//vqrJKlVq1YO6+LjU7Lf9VauXNnueUBAQIHL09PTJclW7yFDhmjIkCEO9/3bb7+5XJ8r33vp0vt/+aXdv/76qz799FOHA2k5e9w6depo/vz5slgsCgwMVGxsrN0XArmu/IycOnVKWVlZmjx5siZPnlzg8U+dOqXY2Ng86yMjIwut38mTJ+Xr6+tUWWecPn1axhiHn/no6GhJl+p7ucJ+DwAAZQ8BGQBgExcXZxvF+mqsXbtWx48f1/r1621njSXZ3Vecq2bNmpo5c6Yk6fvvv9fChQs1atQoXbx4UdOnT7eNNv3f//5XNWvWvOq6uUtuvYcPH6777rvPYZn69euX2LGbNm2qsWPHOlyfG/gKEhgY6NRn4cqBxCpVqmQ765rf2d3cUBweHq6UlJQ86x0tu1LVqlWVnZ2tlJSUfL/IcUWlSpXk4+Oj5OTkPOtyB95yNPI5AMC7EJABAMUuNzTlnlHL9fbbbxe43XXXXaeXXnpJH3/8sXbs2CFJuv322+Xn56dDhw7p/vvvL5kKl4D69eurXr162r17t8aNG+fWY3fr1k3Lly9XnTp17C5/dofg4GB16tRJO3fuVNOmTW1n1h3p1KmTXn/9de3evdvuMut58+YVepwuXbooKSlJ06ZN0+jRo/Mtd+XZ9fyEhITohhtu0KJFi/TGG2/YpqrKycnRhx9+qJiYGF133XWF7gcAULYRkAEAxa5t27aqVKmS+vXrp5EjR8rf319z587V7t277cp98803GjhwoB544AHVq1dPAQEBWrt2rb755hsNGzZM0qWpekaPHq0RI0bo8OHDuuOOO1SpUiX9+uuv2rp1q0JCQuxGRvYkb7/9trp06aLbb79dvXr10rXXXqvff/9d+/fv144dO/Sf//ynRI47evRorVq1Sm3bttUzzzyj+vXrKz09XUeOHNHy5cs1ffr0Ep1jedKkSWrfvr06dOig/v37q1atWkpLS9PBgwf16aefau3atZKkwYMH67333lPXrl01ZswYVatWTXPnztV3331X6DE6dOigRx99VGPGjNGvv/6qbt26yWq1aufOnQoODtagQYMkSU2aNNH8+fO1YMEC1a5dW4GBgWrSpInDfSYlJenWW29Vp06dNGTIEAUEBGjq1Knau3evPvroozxnywEA3oeADAAoduHh4frss8/0/PPP65FHHlFISIi6d++uBQsWqEWLFrZykZGRqlOnjqZOnapjx47JYrGodu3aevPNN20BR7p0mXLDhg01adIkffTRR8rIyFBkZKRatWqlfv36lcZLdEqnTp20detWjR07VoMHD9bp06cVHh6uhg0b6sEHHyyx40ZFRWnbtm167bXX9M9//lM///yzQkNDFRsba/uCoSQ1bNhQO3bs0GuvvaaXXnpJJ06c0DXXXKN69erpzjvvtJWLjIzUhg0blJiYqP79+ys4OFj33nuvpkyZou7duxd6nNmzZ6tFixaaOXOmZs+eraCgIDVs2FAvvviircyrr76q5ORk/f3vf1daWppq1qxpmwbqSh07dtTatWs1cuRI9erVSzk5OWrWrJmWLl2qbt26XfX7AgDwfBZjjCntSgAAAAAAUNqY5gkAAAAAABGQAQAAAACQREAGAAAAAEASARkAAAAAAEkEZAAAAAAAJBGQAQAAAACQVArzIOfk5Oj48eMKDQ2VxWJx9+EBAAAAAOWMMUZpaWmKjo6Wj0/+54ndHpCPHz+u6tWru/uwAAAAAIBy7tixY4qJicl3vdsDcmhoqKRLFatYsaK7Dw8AAAAAKGfOnj2r6tWr2/JoftwekHMvq65YsSIBGQAAAADgNoXd5ssgXQAAAAAAiIAMAAAAAIAkAjIAAAAAAJJK4R5kZ+Tk5OjixYulXQ14uICAgAKHaAcAAAAAV3hcQL548aJ+/PFH5eTklHZV4OF8fHwUGxurgICA0q4KAAAAAC/gUQHZGKPk5GT5+vqqevXqnB1EvnJycnT8+HElJyerRo0ahY5GBwAAAACF8aiAnJWVpfPnzys6OlrBwcGlXR14uKpVq+r48ePKysqSv79/aVcHAAAAKBH7k89qwdfHdOFidmlXRdfHVtb9LWNKuxolxqMCcnb2pQbnklk4I/dzkp2dTUCG5zu6Sdo2S/LxlTr+Q6pcu7RrBAAAPN2hddKuuTp24Hf9+EeC7vb9f/LVpVtRM42f3sx6QCkKV3XLrxrst0i+sg/QF4xVC7Nv0iN+q2zbOXLahGp01qMyDsZwjrGc1GC/j+WnLElSrZ9DpCPXXFrpGyB1elEK857A7FEBOReXy8IZfE5Qppz5Scq6IGVnSmm/EpABAEDhzhyVstIVkHFaTSyHFaZzWpTdQUG6qC6+X6mKJVUpJlzVdFph+kOfZrdR5p8Rr7IlTTf57FIDn59s2zlS3XJSrXy+k7+yddFBQI7QaV2jNH2W3VoZ8le7ilXUvEENKfOC9O0n0h8nCMgAgCLwtV4KyAAAAM7ytdp+DArw0+An/yGf9NOKXHtQ/27VQhlVmyowOVCVd25SzVuflfEPkiT5nz6kqptfU5Na9RRy5Khq3PkPh7sPOr5FlXZN12e3t5e57Fi5AlNCVHnHl6p5S6JMQAWFBflLFQOl879fCshehoBczo0aNUpLlizRrl27Srsq6tWrl86cOaMlS5aUdlUAAAAAj+Njsei6aqHS+UzJ6qcKlYOlaqFSerBk9VO9iApSwJ9jOfmGXCoTGihZ/S5t58iF3G1DJb+8AVkXL9u3NZ99eBGGiS4mKSkpSkxMVN26dRUYGKhq1aqpffv2mj59us6fP1/a1SuSUaNGyWKxFPg4cuSIy/s9cuSILBaLR4RyAAAAAMjFGeRicPjwYbVr107XXHONxo0bpyZNmigrK0vff/+93nvvPUVHR+vuu+92uG1mZqbHDjA1ZMgQ9evXz/a8VatWevLJJ/X3v//dtqxq1aq2ny9evMgAawAAAADKLM4gF4Onn35afn5+2rZtmx588EHFxcWpSZMmuv/++/XZZ5/prrvuspW1WCyaPn26unfvrpCQEI0ZM0aSNG3aNNWpU0cBAQGqX7++PvjgA9s2js64njlzRhaLRevXr5ckrV+/XhaLRWvWrFFCQoKCg4PVtm1bHThwwK6u48ePV7Vq1RQaGqo+ffooPT0939dVoUIFRUZG2h6+vr4KDQ21PR82bJjuv/9+JSUlKTo6Wtddd53tNV55mfQ111yj2bNnS5JiY2MlSfHx8bJYLLrpppvsyr7xxhuKiopSeHi4BgwYoMxM7tkEAAAAUPIIyFfp1KlT+uKLLzRgwACFhIQ4LHPlaMsjR45U9+7dtWfPHvXu3VuLFy9WYmKinn/+ee3du1dPPfWUnnjiCa1bt87l+owYMUJvvvmmtm3bJj8/P/Xu3du2buHChRo5cqTGjh2rbdu2KSoqSlOnTnX5GJdbs2aN9u/fr1WrVmnZsmVObbN161ZJ0urVq5WcnKxFixbZ1q1bt06HDh3SunXrNGfOHM2ePdsWrAHvYUq7AgAAoCwwhfQZCltfHMcq9Bje1a/x+Eus75r8pU6mZbj9uFVDrfp0UPtCyx08eFDGGNWvX99ueZUqVWxnZwcMGKAJEybY1vXo0cMuuPbo0UO9evXS008/LUl67rnntGXLFr3xxhvq1KmTS/UeO3asOnbsKEkaNmyYunbtqvT0dAUGBmrixInq3bu3+vbtK0kaM2aMVq9eXeBZ5MKEhITo3XffdenS6tzLssPDwxUZGWm3rlKlSpoyZYp8fX3VoEEDde3aVWvWrLG7rBsos5iaDAAAuOrP/oOlyEHUuwJsSfP4gHwyLUMpZ4se4NzlyrPEW7duVU5Ojnr27KmMDPuAn5CQYPd8//79evLJJ+2WtWvXTpMmTXK5Hk2bNrX9HBUVJUk6ceKEatSoof3799vdUyxJbdq0KdKZ6lxNmjQp1vuOGzVqJF9fX9vzqKgo7dmzp9j2D5QuAjIAAHCVC/0Hu0yS388oiMcH5KqhDoYa96Dj1q1bVxaLRd99953d8tq1a0uSgoKC8mzj6FLsKwO2Mca2zMfHx7YsV3735V4+4Ffu9jk5OYW+jqLK77WYKy7FcPY+4isHLLNYLCVafwAAAADI5fEB2ZnLnEtTeHi4br31Vk2ZMkWDBg3K9z7kgsTFxenLL7/UY489Zlu2adMmxcXFSfrrkuTk5GTFx8dLUpGmSIqLi9OWLVvsjrNlyxaX91OYqlWrKjk52fb8hx9+sJvqKveMc3Z2drEfGwAAAACKyuMDclkwdepUtWvXTgkJCRo1apSaNm0qHx8fff311/ruu+/UsmXLArd/4YUX9OCDD6pFixbq3LmzPv30Uy1atEirV6+WdOksdOvWrTV+/HjVqlVLv/32m1566SWX65mYmKjHH39cCQkJat++vebOnat9+/bZznYXl5tvvllTpkxR69atlZOTo6FDh9qdGY6IiFBQUJBWrFihmJgYBQYGKiwsrFjrAAAAAACuYhTrYlCnTh3t3LlTt9xyi4YPH65mzZopISFBkydP1pAhQ/Taa68VuP0999yjSZMm6Z///KcaNWqkt99+W7NmzbKb/ui9995TZmamEhISlJiYaJseyhUPPfSQXnnlFQ0dOlQtW7bU0aNH1b9/f5f3U5g333xT1atX14033qgePXpoyJAhCg4Otq338/PTv/71L7399tuKjo5W9+7di70OgEcrzhEnAQAAGIir2HAGuZhERUVp8uTJmjx5coHlrrw3N1f//v0LDKtxcXHavHlzvvu66aab8uy7efPmeZa9+OKLevHFF+2WXT7CdkGOHDli9zy/6Zeio6O1cuVKu2Vnzpyxe963b1/baNoF7W/ixIlO1Q3weIRiAABQREb5DbPlRP+CPohLOIMMAO7CNE8AAMBVl/UfCo+6l/U1bNsVspXT/ZMrynlpv4aADAAAAABlgIXpmkocARkAAAAAABGQAQAAAACQREAGAAAAAECSiwE5KytLL730kmJjYxUUFKTatWtr9OjRysnJKan6AQAAAAAKwkjVxcalaZ4mTJig6dOna86cOWrUqJG2bdumJ554QmFhYUpMTCypOgKAF8h/ggYAAADH/uo/WEp8ruP89l/Icb0sm7sUkDdv3qzu3bura9eukqRatWrpo48+0rZt20qkcgDgVbx0OgQAAFCC/uw/WCzmryzqSp/CmELKO7mvPPvwzn6NS5dYt2/fXmvWrNH3338vSdq9e7e+/PJL3Xnnnfluk5GRobNnz9o9AAAAAADwNC4F5KFDh+rhhx9WgwYN5O/vr/j4eA0ePFgPP/xwvtskJSUpLCzM9qhevfpVV7q8GjVqlJo3b2573qtXL91zzz1Xtc/i2AcAAAAAeAOXAvKCBQv04Ycfat68edqxY4fmzJmjN954Q3PmzMl3m+HDhys1NdX2OHbs2FVX2tP06tVLFotFFotF/v7+ql27toYMGaJz586V6HEnTZqk2bNnO1X2yJEjslgs2rVrV5H3AQAAAADezKV7kF944QUNGzZMf/vb3yRJTZo00dGjR5WUlKTHH3/c4TZWq1VWq/Xqa+rh7rjjDs2aNUuZmZn63//+p759++rcuXOaNm2aXbnMzEz5+/sXyzHDwsI8Yh8AXOVlo1kAAAB4CZfOIJ8/f14+Pvab+Pr6Ms2TLn0REBkZqerVq6tHjx7q2bOnlixZYrss+r333lPt2rVltVpljFFqaqqefPJJRUREqGLFirr55pu1e/duu32OHz9e1apVU2hoqPr06aP09HS79VdeHp2Tk6MJEyaobt26slqtqlGjhsaOHStJio2NlSTFx8fLYrHopptucriPjIwMPfPMM4qIiFBgYKDat2+vr7/+2rZ+/fr1slgsWrNmjRISEhQcHKy2bdvqwIEDxfhuAgAAACh0+qbi/M49v2MVOoWUd33x71JAvuuuuzR27Fh99tlnOnLkiBYvXqy33npL9957b0nVr8wKCgpSZmamJOngwYNauHChPv74Y9slzl27dlVKSoqWL1+u7du3q0WLFurcubN+//13SdLChQs1cuRIjR07Vtu2bVNUVJSmTp1a4DGHDx+uCRMm6OWXX9a3336refPmqVq1apKkrVu3SpJWr16t5ORkLVq0yOE+/vGPf+jjjz/WnDlztGPHDtWtW1e33367rV65RowYoTfffFPbtm2Tn5+fevfuXeT3CgAAAEDBvHPMaM/j0iXWkydP1ssvv6ynn35aJ06cUHR0tJ566im98sorJVU/KStDOvtLye0/PxWvlfyKdmn41q1bNW/ePHXu3FmSdPHiRX3wwQeqWrWqJGnt2rXas2ePTpw4Ybv8/I033tCSJUv03//+V08++aQmTpyo3r17q2/fvpKkMWPGaPXq1XnOIudKS0vTpEmTNGXKFNvl7nXq1FH79u0lyXbs8PBwRUZGOtxH7iXhs2fPVpcuXSRJM2bM0KpVqzRz5ky98MILtrJjx45Vx44dJUnDhg1T165dlZ6ersDAwCK9Z0D5wJ82AADgqr/6D8Y21VI+fYp8p3MqgT6Il05f6VJADg0N1cSJEzVx4sQSqo4DZ3+RVgx33/Fy3ZEkVa7tdPFly5apQoUKysrKUmZmprp3767Jkydr6tSpqlmzpi2gStL27dv1xx9/KDw83G4fFy5c0KFDhyRJ+/fvV79+/ezWt2nTRuvWrXN4/P379ysjI8MWyovi0KFDyszMVLt27WzL/P39df3112v//v12ZZs2bWr7OSoqSpJ04sQJ1ahRo8jHBwAAAIDS5FJALhUVr70UVkvjuC7o1KmTpk2bJn9/f0VHR9sNxBUSEmJXNicnR1FRUVq/fn2e/VxzzTVFqa2CgoKKtN3lzJ/3F1iu+DbIGJNn2eWvL3cd96IDAAAAKMs8PyD7WV06k1taQkJCVLduXafKtmjRQikpKfLz81OtWrUclomLi9OWLVv02GOP2ZZt2bIl333Wq1dPQUFBWrNmje2y7MsFBARIkrKzs/PdR926dRUQEKAvv/xSPXr0kHRp1O1t27Zp8ODBTrwyAAAAACi7PD8ge6FbbrlFbdq00T333KMJEyaofv36On78uJYvX6577rlHCQkJSkxM1OOPP66EhAS1b99ec+fO1b59+1S7tuMvCwIDAzV06FD94x//UEBAgNq1a6eTJ09q37596tOnjyIiIhQUFKQVK1YoJiZGgYGBeaZ4CgkJUf/+/fXCCy+ocuXKqlGjhl5//XWdP39effr0ccdbA5QPhY4GCQAA4Ar6FsWFgFwKLBaLli9frhEjRqh37946efKkIiMjdeONN9pGnX7ooYd06NAhDR06VOnp6br//vvVv39/rVy5Mt/9vvzyy/Lz89Mrr7yi48ePKyoqynYfs5+fn/71r39p9OjReuWVV9ShQweHl3iPHz9eOTk5evTRR5WWlqaEhAStXLlSlSpVKpH3Aig3CMUAAMBll/oPl7oRjvoSTvQvnO6D0FeRJIsx7u21nT17VmFhYUpNTVXFihXt1qWnp+vHH39UbGwsoyGjUHxeUKbsnCsd/X/S+VNSm4FSbIfSrhEAAPB0X78r/bJDa3fs196cGmoZlKJ2I1ZKF85Ii5+SbnxBikmQjnwpbZosPfj+XzPxnDokrXxRqnOzdHiD9PA8x8c4uln6fxOl/3tPCghxfn16qrToyb/q4OEKyqGXc2keZAAAAABA6bANm+vMdE6WfH7Os4mz0zV557ROVyIgAwAAAAAgAjIAAAAAAJIIyAAAAAAASCIgA0ApYJRIAABQjJgto9h4ZEB288DaKKP4nKBsMSovg1sAAIDidJX9h6vuMxeyvZf1yT1qHmR/f39ZLBadPHlSVatWlcXpEdVQ3hhjdPLkSVksFvn7+5d2dQDn8L80AADgKstf/zEudSaKeXTqPNnMOzs2HhWQfX19FRMTo59//llHjhwp7erAw1ksFsXExMjX17e0qwIAAADAC3hUQJakChUqqF69esrMzCztqsDD+fv7E44BAAAAFBuPC8jSpTPJBB8AAAAAgDt55CBdAAAAAABneddAWaWJgAwAAAAAgAjIAOAeXjYFAgAAcIPL+g8WR2eJnepfONkHyW9fhR7Du/o4BGQAcBvvnA4BAACUJIuDn/PpUziaJrfYvqS/Yt9eOiUvARkAAAAAABGQAQAAAACQREAGAAAAAEASARkA3I8BuwAAADwSARkAAAAAPJzDUayLdQTpIu7Ly774JyADgLt46WiPAACgBP3Zfyh6L8K7AmxJIyADgNsQkAEAgKsc9B/y/dLd4rhMQV/S8wW+HQIyAAAAAJQFZNkSR0AGAAAAAEAEZAAoBdwLBAAAipGXDZRVmgjIAAAAAACIgAwAbsI3uwAAoJg5c+b4qs8ul68+DAEZAAAAADyc43mQUdwIyADgLkyjAAAAXGXXf3ClL+FsWSfL5enHeGe/hoAMAAAAAIAIyAAAAAAASCpCQP7ll1/0yCOPKDw8XMHBwWrevLm2b99eEnUDAAAAABSK+5OLi58rhU+fPq127dqpU6dO+vzzzxUREaFDhw7pmmuuKaHqAQAAAADgHi4F5AkTJqh69eqaNWuWbVmtWrWKu04A4H2MkbcOZgEAAErIn/2Hq+tFOHl2Ob/poAqdJsq7zl67dIn10qVLlZCQoAceeEARERGKj4/XjBkzSqpuAAAAAABJkrksiuYTlx3NmFHYl/ROz7JxRTkvnZ3DpYB8+PBhTZs2TfXq1dPKlSvVr18/PfPMM3r//ffz3SYjI0Nnz561ewAAAAAAXOOdkdSzuHSJdU5OjhISEjRu3DhJUnx8vPbt26dp06bpsccec7hNUlKSXn311auvKQAAAAAAJcilM8hRUVFq2LCh3bK4uDj99NNP+W4zfPhwpaam2h7Hjh0rWk0BwFsUei8PAAAASoNLZ5DbtWunAwcO2C37/vvvVbNmzXy3sVqtslqtRasdAAAAAABu4tIZ5GeffVZbtmzRuHHjdPDgQc2bN0/vvPOOBgwYUFL1AwAAAIDyjavP3MalgNyqVSstXrxYH330kRo3bqzXXntNEydOVM+ePUuqfgDgPbx0tEcAAFBSTCH9B2eCs7PhOr9yhWzvZeHdpUusJalbt27q1q1bSdQFALwcARkAALjK8ue/lwXRfEOzxXEZvqR3mktnkAEAAAAA8FYEZAAAAAAAREAGgFLgXffqAACAUuZl9wGXJgIyAAAAAAAiIAOAm/DNLgAAcNFlZ4YdDrPlzJljzi67hIAMAAAAAF6LgOwKAjIAuAtTLAAAAFdd1n8whfUl7NY72+9wslyeY3tnv4aADAAAAACACMgAAAAAUMZxGXVxISADAAAAACACMgAAAAAAkgjIAOAeTLEAAACKyEiylPRl1Pn1VQrtw3hXH4eADABu452jPQIAgJJk+fPfIgZRvqR3CQEZANyFaZ4AAICrHE7d5ESfwtkpn5zunlxR0Ev7NQRkAAAAAABEQAYA9+NSJwAAAI9EQAYAAAAAQARkAAAAAAAkEZABAAAAwEMVxxRLzt7alV+5Qrb3slvHCMgAAAAA4LEstn9N7kjS+Y0g7eryq8Io1gAAAAAAeC0CMgC4nXddigQAAEqZl13mXJoIyAAAAAAAiIAMAAAAAIAkAjIAAAAAeCzDrVluRUAGALfgjxsAAHCRMfprFGsHfQln7j129v5k7mOWREAGADeyyFunRAAAACXLPiA705/ILWNUcHkn+yYlMlWU5yEgAwAAAEAZUD4iaukiIAOAu3EFEwAAKFZ0LooLARkAAAAAABGQAQAAAACQREAGAPdgZEgAAFAarrYLUs76MARkAAAAAPBUHj96tHcFaAIyALiLx/+BAwAAnseSz88FlZPz/Q6n+ydF3H8ZQ0AGAAAAgLLMu07ilioCMgAAAAAAusqAnJSUJIvFosGDBxdTdQAAAAAAKB1FDshff/213nnnHTVt2rQ46wMAAAAAQKkoUkD+448/1LNnT82YMUOVKlUq7joBgBfi5iAAAOAqY+tBWBz2JZzpX1z1PE+FrPauPk6RAvKAAQPUtWtX3XLLLYWWzcjI0NmzZ+0eAAAAAABnXOVo0V4WYEuan6sbzJ8/Xzt27NDXX3/tVPmkpCS9+uqrLlcMALySl06JAAAASp7J7Ue42p8ojv5Hnn14Z5/GpTPIx44dU2Jioj788EMFBgY6tc3w4cOVmppqexw7dqxIFQUA78E3uQAAAJ7IpTPI27dv14kTJ9SyZUvbsuzsbG3cuFFTpkxRRkaGfH197baxWq2yWq3FU1sAAAAAAEqISwG5c+fO2rNnj92yJ554Qg0aNNDQoUPzhGMAAAAAAMoKlwJyaGioGjdubLcsJCRE4eHheZYDAAAAAFCWFHkeZAAAAABACbpsBGqH0zwV5wjVRd6Xd42t4vIo1ldav359MVQDAAAAAJDHn6NHF33MaO8KsCWNM8gA4DYWeeuUCAAAoKRYCvzpr0UFTcNUUP+DvsnlCMgA4G7FeTkUAAAAZ4mLDQEZAAAAAAARkAEAAAAAkERABgAAAACPxcXT7kVABgB34L5jAABwFRxO8+RMfL7aPkg568MQkAHAXSwWByNMAgAAFOCyrkPBUfWKPoazfY6ilvPSPg0BGQAAAADKhHxCaTk7y1uSCMgAAAAAAIiADAAAAACAJAIyAAAAAACSCMgAAAAA4KGMbWQux6NYO7mPqypXvu5vJiADAAAAgKf6c7ToIo8ZXdIDeHnZAGEEZABwG++cDgEAALiZoymWCpp2qcApmYraP/HOfg0BGQDczru+aQUAAPAWBGQAAAAAAERABgAAAABAEgEZAAAAAABJBGQAAAAA8EzGFDxyiVMjSDs59kl++ypnQ6cQkAEAAADAY+VO8+SpSdVT61U0BGQAcDcvmy8QAACUIIdTNF25zFHfwpLPz0WqxFVuX3YQkAEAAAAAEAEZAAAAAABJBGQAAAAAACQRkAEAAADAczF0iVsRkAHAHRiYCwAAuMzk83NBy64sQh/EFQRkAAAAAPBUDkexdgUB2RUEZABwF4vlzz9y/KECAABFkF9YdnSW2NlgXdQAftXB3TMRkAEAAAAAEAEZAAAAAABJBGQAAAAAACQRkAEAAAAAkERABgA3YWAuAABQFJbL/i1J+fVVCunDeNk0UgRkAAAAAPBYuQHZyOTG5DwjSBsHy/58bhytc1CuwCo4KsMo1gAAAAAAeC0CMgAAAAAAcjEgJyUlqVWrVgoNDVVERITuueceHThwoKTqBgAAAACA27gUkDds2KABAwZoy5YtWrVqlbKysnTbbbfp3LlzJVU/AAAAAADcws+VwitWrLB7PmvWLEVERGj79u268cYbi7ViAOBVvGyERwAA4AbG2MaQdjgkllP9Cyf7IPntq5z1YVwKyFdKTU2VJFWuXDnfMhkZGcrIyLA9P3v27NUcEgAAAADgMbwrQBd5kC5jjJ577jm1b99ejRs3zrdcUlKSwsLCbI/q1asX9ZAA4AUs5e6bWAAAcDUsDn52dYqlq52SycH2BU4dVXYVOSAPHDhQ33zzjT766KMCyw0fPlypqam2x7Fjx4p6SAAAAAAASkyRLrEeNGiQli5dqo0bNyomJqbAslarVVartUiVAwAAAADAXVwKyMYYDRo0SIsXL9b69esVGxtbUvUCAAAAAMCtXArIAwYM0Lx58/TJJ58oNDRUKSkpkqSwsDAFBQWVSAUBAAAAAHAHl+5BnjZtmlJTU3XTTTcpKirK9liwYEFJ1Q8AAAAAyimj3FGiLQ5Hi3Zi4E+nBwdlEFGpCJdYAwCuFv8vBQAATvpztGjHAflPBeY0+h2uKPIo1gAAF1ksXjslAgAAcAPbLE+O+hNXLLu8TEH9D2f6JuWo/0JABgAAAABABGQAAAAAACQRkAEAAAAAkERABgAAAACPxTjJ7kVABgC34K8bAAAoBVedsAvZ3ssSPAEZAAAAADxcwQNJe1dILU0EZABwm/IzRQIAACgmdsnYlemanO13FLF/4qVTPxGQAQAAAAAQARkAAAAAAEkEZAAAAAAAJBGQAQAAAACQREAGAPe4fAoEL5sOAQAAlJDL+gwWRyNVO9WncLLfkd++Cj2Gd/VrCMgA4FbeOeIjAAAoKRYZW//hz/+6MoK0MaL/4TwCMgAAAAAAIiADAAAAACCJgAwAAAAAgCQCMgAAAAAAkgjIAAAAAOChjIxtlGhHo0UX5wjS+e3Lu0apLgwBGQDcrnz9oQEAAFevwHGoS3MKSS/r1hCQAcBdLBbXpmUAAABweoqmK8pd3ucoqP/hTN8k3zLe168hIAMAAAAAIAIyAAAAAACSCMgAAAAAAEgiIAMAAAAAIImADABu4mVDPAIAALeyOOpLONO9KM0RrssgAjIAAAAAlGmE4OJCQAYAt7HIG6dDAAAAJe3P/oPddEsFTOtUlH1DEgEZAAAAAABJBGQAAAAAACQRkAEAAAAAkERABgAAAACPxfBb7kVABgB3uHyKBaZbAAAAzrisz+BwmifnduLysZxa7qUIyAAAAADg4Yo81nSJB1zvCtAEZABwlyJPvwAAAMqvv84dmwJjchHXOdU/yaeMF/ZtihSQp06dqtjYWAUGBqply5b63//+V9z1AgAAAADArVwOyAsWLNDgwYM1YsQI7dy5Ux06dFCXLl30008/lUT9AAAAAABwC5cD8ltvvaU+ffqob9++iouL08SJE1W9enVNmzatJOoHAAAAAIBb+LlS+OLFi9q+fbuGDRtmt/y2227Tpk2birVipWnF3mSt++5kaVcDgBfp8NtxhWSdUeXMM9p99qj2fftNaVcJAAB4uE4nUqScLAaOciOXAvJvv/2m7OxsVatWzW55tWrVlJKS4nCbjIwMZWRk2J6fPXu2CNV0rz2/pKrWrtcVZTlV2lUB4CX8dVHfmmjFWNJV5felaqPlpV0lAADg4Sy6qH05tdTQx0chuiCLpeJfK318pZ3vS9/Ml7IyJF9/+419fC/998xRKbhyAQf5M35/8dJf21wuKyP/wbhMjvT1u1LtTpKvS9HSYxXpVViueIOMMXmW5UpKStKrr75alMOUqk05jRSq86VdDQBe5ICproo6z5dvAADAad+amtqU01DVfM7onubt/lrRZqD0x2UnKSvG2G9orSjd8JSUnipVqpX/ASrFSi17SVnp+ZcJjXa8vN3gS3WweM85bosxzk+MdfHiRQUHB+s///mP7r33XtvyxMRE7dq1Sxs2bMizjaMzyNWrV1dqaqoqVqyYp7wnOJmWodPnL5Z2NQAAAABAklQpOEBVQ62lXY0y6+zZswoLCys0h7p0BjkgIEAtW7bUqlWr7ALyqlWr1L17d4fbWK1WWa1lqyGrhlr58AEAAABAOePyJdbPPfecHn30USUkJKhNmzZ655139NNPP6lfv34lUT8AAAAAANzC5YD80EMP6dSpUxo9erSSk5PVuHFjLV++XDVr1iyJ+gEAAAAA4BYu3YNcHJy99hsAAAAAgOLgbA71nuHGAAAAAAC4CgRkAAAAAABEQAYAAAAAQFIRBum6Wrm3PJ89e9bdhwYAAAAAlEO5+bOwIbjcHpDT0tIkSdWrV3f3oQEAAAAA5VhaWprCwsLyXe/2UaxzcnJ0/PhxhYaGymKxuPPQLjl79qyqV6+uY8eOMdq2F6OdvR9tXD7QzuUD7Vw+0M7lA+3s/TytjY0xSktLU3R0tHx88r/T2O1nkH18fBQTE+PuwxZZxYoVPaJBUbJoZ+9HG5cPtHP5QDuXD7Rz+UA7ez9PauOCzhznYpAuAAAAAABEQAYAAAAAQBIBOV9Wq1UjR46U1Wot7aqgBNHO3o82Lh9o5/KBdi4faOfygXb2fmW1jd0+SBcAAAAAAJ6IM8gAAAAAAIiADAAAAACAJAIyAAAAAACSCMgAAAAAAEgiIDs0depUxcbGKjAwUC1bttT//ve/0q4S8rFx40bdddddio6OlsVi0ZIlS+zWG2M0atQoRUdHKygoSDfddJP27dtnVyYjI0ODBg1SlSpVFBISorvvvls///yzXZnTp0/r0UcfVVhYmMLCwvToo4/qzJkzJfzqkCspKUmtWrVSaGioIiIidM899+jAgQN2ZWjrsm/atGlq2rSpKlasqIoVK6pNmzb6/PPPbetpY++TlJQki8WiwYMH25bRzmXfqFGjZLFY7B6RkZG29bSx9/jll1/0yCOPKDw8XMHBwWrevLm2b99uW09bl321atXK8/tssVg0YMAASV7axgZ25s+fb/z9/c2MGTPMt99+axITE01ISIg5evRoaVcNDixfvtyMGDHCfPzxx0aSWbx4sd368ePHm9DQUPPxxx+bPXv2mIceeshERUWZs2fP2sr069fPXHvttWbVqlVmx44dplOnTqZZs2YmKyvLVuaOO+4wjRs3Nps2bTKbNm0yjRs3Nt26dXPXyyz3br/9djNr1iyzd+9es2vXLtO1a1dTo0YN88cff9jK0NZl39KlS81nn31mDhw4YA4cOGBefPFF4+/vb/bu3WuMoY29zdatW02tWrVM06ZNTWJiom057Vz2jRw50jRq1MgkJyfbHidOnLCtp429w++//25q1qxpevXqZb766ivz448/mtWrV5uDBw/aytDWZd+JEyfsfpdXrVplJJl169YZY7yzjQnIV7j++utNv3797JY1aNDADBs2rJRqBGddGZBzcnJMZGSkGT9+vG1Zenq6CQsLM9OnTzfGGHPmzBnj7+9v5s+fbyvzyy+/GB8fH7NixQpjjDHffvutkWS2bNliK7N582YjyXz33Xcl/KrgyIkTJ4wks2HDBmMMbe3NKlWqZN59913a2MukpaWZevXqmVWrVpmOHTvaAjLt7B1GjhxpmjVr5nAdbew9hg4datq3b5/vetraOyUmJpo6deqYnJwcr21jLrG+zMWLF7V9+3bddtttdstvu+02bdq0qZRqhaL68ccflZKSYteeVqtVHTt2tLXn9u3blZmZaVcmOjpajRs3tpXZvHmzwsLCdMMNN9jKtG7dWmFhYXwuSklqaqokqXLlypJoa2+UnZ2t+fPn69y5c2rTpg1t7GUGDBigrl276pZbbrFbTjt7jx9++EHR0dGKjY3V3/72Nx0+fFgSbexNli5dqoSEBD3wwAOKiIhQfHy8ZsyYYVtPW3ufixcv6sMPP1Tv3r1lsVi8to0JyJf57bfflJ2drWrVqtktr1atmlJSUkqpViiq3DYrqD1TUlIUEBCgSpUqFVgmIiIiz/4jIiL4XJQCY4yee+45tW/fXo0bN5ZEW3uTPXv2qEKFCrJarerXr58WL16shg0b0sZeZP78+dqxY4eSkpLyrKOdvcMNN9yg999/XytXrtSMGTOUkpKitm3b6tSpU7SxFzl8+LCmTZumevXqaeXKlerXr5+eeeYZvf/++5L4ffZGS5Ys0ZkzZ9SrVy9J3tvGfm4/YhlgsVjsnhtj8ixD2VGU9ryyjKPyfC5Kx8CBA/XNN9/oyy+/zLOOti776tevr127dunMmTP6+OOP9fjjj2vDhg229bRx2Xbs2DElJibqiy++UGBgYL7laOeyrUuXLrafmzRpojZt2qhOnTqaM2eOWrduLYk29gY5OTlKSEjQuHHjJEnx8fHat2+fpk2bpscee8xWjrb2HjNnzlSXLl0UHR1tt9zb2pgzyJepUqWKfH1983xTceLEiTzfjMDz5Y6YWVB7RkZG6uLFizp9+nSBZX799dc8+z958iSfCzcbNGiQli5dqnXr1ikmJsa2nLb2HgEBAapbt64SEhKUlJSkZs2aadKkSbSxl9i+fbtOnDihli1bys/PT35+ftqwYYP+9a9/yc/Pz9YGtLN3CQkJUZMmTfTDDz/wu+xFoqKi1LBhQ7tlcXFx+umnnyTxt9nbHD16VKtXr1bfvn1ty7y1jQnIlwkICFDLli21atUqu+WrVq1S27ZtS6lWKKrY2FhFRkbatefFixe1YcMGW3u2bNlS/v7+dmWSk5O1d+9eW5k2bdooNTVVW7dutZX56quvlJqayufCTYwxGjhwoBYtWqS1a9cqNjbWbj1t7b2MMcrIyKCNvUTnzp21Z88e7dq1y/ZISEhQz549tWvXLtWuXZt29kIZGRnav3+/oqKi+F32Iu3atcsz5eL333+vmjVrSuJvs7eZNWuWIiIi1LVrV9syr21jtw0HVkbkTvM0c+ZM8+2335rBgwebkJAQc+TIkdKuGhxIS0szO3fuNDt37jSSzFtvvWV27txpm5Zr/PjxJiwszCxatMjs2bPHPPzwww6Hno+JiTGrV682O3bsMDfffLPDoeebNm1qNm/ebDZv3myaNGnC9AJu1L9/fxMWFmbWr19vN9XA+fPnbWVo67Jv+PDhZuPGjebHH38033zzjXnxxReNj4+P+eKLL4wxtLG3unwUa2NoZ2/w/PPPm/Xr15vDhw+bLVu2mG7dupnQ0FBbX4o29g5bt241fn5+ZuzYseaHH34wc+fONcHBwebDDz+0laGtvUN2drapUaOGGTp0aJ513tjGBGQH/v3vf5uaNWuagIAA06JFC9tUMvA869atM5LyPB5//HFjzKUpBkaOHGkiIyON1Wo1N954o9mzZ4/dPi5cuGAGDhxoKleubIKCgky3bt3MTz/9ZFfm1KlTpmfPniY0NNSEhoaanj17mtOnT7vpVcJRG0sys2bNspWhrcu+3r172/7fW7VqVdO5c2dbODaGNvZWVwZk2rnsy50H1d/f30RHR5v77rvP7Nu3z7aeNvYen376qWncuLGxWq2mQYMG5p133rFbT1t7h5UrVxpJ5sCBA3nWeWMbW4wxxv3nrQEAAAAA8CzcgwwAAAAAgAjIAAAAAABIIiADAAAAACCJgAwAAAAAgCQCMgAAAAAAkgjIAAAAAABIIiADAAAAACCJgAwAAAAAgCQCMgAAAAAAkgjIAAAAAABIIiADAAAAACCJgAwAAAAAgCTp/wM+X/mYGqgZKAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done âœ…\n"
     ]
    }
   ],
   "source": [
    "# visualize a random validation video prediction\n",
    "idx = np.random.randint(len(val_ds))\n",
    "X, y = val_ds[idx]\n",
    "with torch.no_grad():\n",
    "    pred = model(X.unsqueeze(0).to(device)).squeeze(0).cpu().numpy().argmax(0)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(y, label='Ground Truth', lw=2)\n",
    "plt.plot(pred, label='Prediction', lw=1, alpha=0.7)\n",
    "plt.legend(); plt.title(\"Phase Timeline Prediction\"); plt.show()\n",
    "\n",
    "print(\"Done âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a375a76-0506-4857-95ef-7f947538d6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60559240-2404-4fb0-9d3f-efd7dd1e80c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
